# FactorLLM: Factorizing Knowledge via Mixture of Experts for Large Language Models
![Python 3.9](https://img.shields.io/badge/Python-3.9-red)
[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/pdf/2405.16486)

<img src="factorllm.png"/>

## To be updated

## Citation
Please cite our work if you find it useful.
```bibtex
@article{zhao2024factorllm,
  title={FactorLLM: Factorizing Knowledge via Mixture of Experts for Large Language Models},
  author={Zhao, Zhongyu and Dong, Menghang and Zhang, Rongyu and Zheng, Wenzhao and Zhang, Yunpeng and Yang, Huanrui and Du, Dalong and Keutzer, Kurt and Zhang, Shanghang},
  journal={arXiv preprint arXiv:2408.11855},
  year={2024}
}
```
